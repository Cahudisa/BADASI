{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5440aa0a",
   "metadata": {},
   "source": [
    "SINCRONIZAR REDNE_plantilla.hdf5 Y  mongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4100c8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sincronización con versionamiento finalizada.\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "from pymongo import MongoClient\n",
    "from datetime import datetime\n",
    "\n",
    "# --- Conexión con usuario y autenticación ---\n",
    "MONGO_URI = \"mongodb://Escritor:123456@localhost:27017/redne?authSource=redne\"\n",
    "client = MongoClient(MONGO_URI)\n",
    "\n",
    "# Base de datos y colecciones\n",
    "db = client[\"redne\"]\n",
    "col_main = db[\"metadatos_EV\"]\n",
    "col_versions = db[\"metadatos_EV_versiones\"]\n",
    "\n",
    "# --- Leer HDF5 ---\n",
    "with h5py.File(\"REDNE_plantilla.hdf5\", \"r\") as f:\n",
    "    data_group = f[\"data\"]\n",
    "\n",
    "    for trace_name in data_group.keys():\n",
    "\n",
    "        trace_group = data_group[trace_name]\n",
    "        metadata = {}\n",
    "\n",
    "        # Extraer atributos del HDF5\n",
    "        for key, val in trace_group.attrs.items():\n",
    "            if key == \"metadata\":\n",
    "                continue\n",
    "            try:\n",
    "                metadata[key] = val.item() if hasattr(val, \"item\") else val\n",
    "            except:\n",
    "                metadata[key] = str(val)\n",
    "\n",
    "        metadata[\"_id\"] = trace_name  # ID del documento\n",
    "\n",
    "        # --- Buscar si ya existe ---\n",
    "        existing_doc = col_main.find_one({\"_id\": trace_name})\n",
    "\n",
    "        if existing_doc is None:\n",
    "            # ---------------------------\n",
    "            #  CASO 1: DOCUMENTO NUEVO\n",
    "            # ---------------------------\n",
    "\n",
    "            metadata[\"version\"] = 1  # primera versión\n",
    "\n",
    "            # Insertar en colección principal\n",
    "            col_main.insert_one(metadata)\n",
    "\n",
    "            # Insertar versión en colección histórica\n",
    "            col_versions.insert_one({\n",
    "                \"trace_id\": trace_name,\n",
    "                \"version\": 1,\n",
    "                \"fecha\": datetime.utcnow().isoformat(),\n",
    "                \"metadata\": metadata\n",
    "            })\n",
    "\n",
    "        else:\n",
    "            # ---------------------------\n",
    "            #  CASO 2: DOCUMENTO EXISTENTE\n",
    "            #     → CREAR NUEVA VERSIÓN\n",
    "            # ---------------------------\n",
    "\n",
    "            nueva_version = existing_doc[\"version\"] + 1\n",
    "            metadata[\"version\"] = nueva_version\n",
    "\n",
    "            # Actualizar documento principal\n",
    "            col_main.update_one(\n",
    "                {\"_id\": trace_name},\n",
    "                {\"$set\": metadata}\n",
    "            )\n",
    "\n",
    "            # Registrar cambios en coleccion de versiones\n",
    "            col_versions.insert_one({\n",
    "                \"trace_id\": trace_name,\n",
    "                \"version\": nueva_version,\n",
    "                \"fecha\": datetime.utcnow().isoformat(),\n",
    "                \"metadata\": metadata\n",
    "            })\n",
    "\n",
    "print(\"\\nSincronización con versionamiento finalizada.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f527ad4",
   "metadata": {},
   "source": [
    "SINCRONIZAR REDNE_plantilla_noise.hdf5 Y  mongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fb96324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sincronización con versionamiento finalizada.\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "from pymongo import MongoClient\n",
    "from datetime import datetime\n",
    "\n",
    "# --- Conexión con usuario y autenticación ---\n",
    "MONGO_URI = \"mongodb://Escritor:123456@localhost:27017/redne?authSource=redne\"\n",
    "client = MongoClient(MONGO_URI)\n",
    "\n",
    "# Base de datos y colecciones\n",
    "db = client[\"redne\"]\n",
    "col_main = db[\"metadatos_NO\"]\n",
    "col_versions = db[\"metadatos_NO_versiones\"]\n",
    "\n",
    "# --- Leer HDF5 ---\n",
    "with h5py.File(\"REDNE_plantilla_noise.hdf5\", \"r\") as f:\n",
    "    data_group = f[\"data\"]\n",
    "\n",
    "    for trace_name in data_group.keys():\n",
    "\n",
    "        trace_group = data_group[trace_name]\n",
    "        metadata = {}\n",
    "\n",
    "        # Extraer atributos del HDF5\n",
    "        for key, val in trace_group.attrs.items():\n",
    "            if key == \"metadata\":\n",
    "                continue\n",
    "            try:\n",
    "                metadata[key] = val.item() if hasattr(val, \"item\") else val\n",
    "            except:\n",
    "                metadata[key] = str(val)\n",
    "\n",
    "        metadata[\"_id\"] = trace_name  # ID del documento\n",
    "\n",
    "        # --- Buscar si ya existe ---\n",
    "        existing_doc = col_main.find_one({\"_id\": trace_name})\n",
    "\n",
    "        if existing_doc is None:\n",
    "            # ---------------------------\n",
    "            #  CASO 1: DOCUMENTO NUEVO\n",
    "            # ---------------------------\n",
    "\n",
    "            metadata[\"version\"] = 1  # primera versión\n",
    "\n",
    "            # Insertar en colección principal\n",
    "            col_main.insert_one(metadata)\n",
    "\n",
    "            # Insertar versión en colección histórica\n",
    "            col_versions.insert_one({\n",
    "                \"trace_id\": trace_name,\n",
    "                \"version\": 1,\n",
    "                \"fecha\": datetime.utcnow().isoformat(),\n",
    "                \"metadata\": metadata\n",
    "            })\n",
    "\n",
    "        else:\n",
    "            # ---------------------------\n",
    "            #  CASO 2: DOCUMENTO EXISTENTE\n",
    "            #     → CREAR NUEVA VERSIÓN\n",
    "            # ---------------------------\n",
    "\n",
    "            nueva_version = existing_doc[\"version\"] + 1\n",
    "            metadata[\"version\"] = nueva_version\n",
    "\n",
    "            # Actualizar documento principal\n",
    "            col_main.update_one(\n",
    "                {\"_id\": trace_name},\n",
    "                {\"$set\": metadata}\n",
    "            )\n",
    "\n",
    "            # Registrar cambios en coleccion de versiones\n",
    "            col_versions.insert_one({\n",
    "                \"trace_id\": trace_name,\n",
    "                \"version\": nueva_version,\n",
    "                \"fecha\": datetime.utcnow().isoformat(),\n",
    "                \"metadata\": metadata\n",
    "            })\n",
    "\n",
    "print(\"\\nSincronización con versionamiento finalizada.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d543afb4",
   "metadata": {},
   "source": [
    "Ingresar varios metadatos al la base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899785b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from insertupdate import guardar_o_actualizar\n",
    "\n",
    "df = pd.read_csv(\"nuevos_metadatos.csv\")    #dirección del archivo\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    documento = row.to_dict()\n",
    "    guardar_o_actualizar(documento)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bf3140",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from insertupdate import guardar_o_actualizar\n",
    "\n",
    "with open(\"nuevos_metadatos.json\", \"r\") as f:    #dirección del archivo\n",
    "    data = json.load(f)\n",
    "\n",
    "for item in data:\n",
    "    guardar_o_actualizar(item)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0228c0c8",
   "metadata": {},
   "source": [
    "Escoger versión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee367502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Documentos restaurados: 6432\n",
      "Documentos sin versión 1: []\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "# --- Conexión ---\n",
    "MONGO_URI = \"mongodb://Escritor:123456@localhost:27017/redne?authSource=redne\"\n",
    "client = MongoClient(MONGO_URI)\n",
    "\n",
    "db = client[\"redne\"]\n",
    "col_actual = db[\"metadatos_EV\"]\n",
    "col_versiones = db[\"metadatos_EV_versiones\"]\n",
    "\n",
    "# === CONFIGURACIÓN ===\n",
    "VERSION_OBJETIVO = 1  # <-- la versión a restaurar\n",
    "# ======================\n",
    "\n",
    "# Buscar todos los documentos actuales\n",
    "docs = list(col_actual.find({}))\n",
    "\n",
    "restaurados = 0\n",
    "no_encontrados = []\n",
    "\n",
    "for doc in docs:\n",
    "    tid = doc[\"_id\"]\n",
    "\n",
    "    # buscar versión antigua\n",
    "    version_ant = col_versiones.find_one({\n",
    "        \"trace_id\": tid, \n",
    "        \"version\": VERSION_OBJETIVO\n",
    "    })\n",
    "\n",
    "    if not version_ant:\n",
    "        no_encontrados.append(tid)\n",
    "        continue\n",
    "\n",
    "    # obtener metadatos guardados\n",
    "    metadata = version_ant[\"metadata\"].copy()\n",
    "    metadata[\"version\"] = VERSION_OBJETIVO  # restaurar versión\n",
    "\n",
    "    # sobrescribir documento actual\n",
    "    col_actual.replace_one({\"_id\": tid}, metadata)\n",
    "    restaurados += 1\n",
    "\n",
    "print(f\"\\nDocumentos restaurados: {restaurados}\")\n",
    "print(f\"Documentos sin versión {VERSION_OBJETIVO}: {no_encontrados}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190d3a85",
   "metadata": {},
   "source": [
    "Crear nuevo .hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc46f036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trazas a incluir: 59\n",
      "Copiada: UIS11.UX_20240425183448_EV\n",
      "Copiada: UIS11.UX_20240425035247_EV\n",
      "Copiada: UIS11.UX_20240425065930_EV\n",
      "Copiada: UIS11.UX_20240405150910_EV\n",
      "Copiada: UIS11.UX_20240405120804_EV\n",
      "Copiada: UIS11.UX_20240414080642_EV\n",
      "Copiada: UIS11.UX_20240502224553_EV\n",
      "Copiada: UIS11.UX_20240406014428_EV\n",
      "Copiada: UIS11.UX_20240423210823_EV\n",
      "Copiada: UIS11.UX_20240430213045_EV\n",
      "Copiada: UIS11.UX_20240511102928_EV\n",
      "Copiada: UIS11.UX_20240423164235_EV\n",
      "Copiada: UIS11.UX_20240417203134_EV\n",
      "Copiada: UIS11.UX_20240509235646_EV\n",
      "Copiada: UIS11.UX_20240406165125_EV\n",
      "Copiada: UIS11.UX_20240414124442_EV\n",
      "Copiada: UIS11.UX_20240416082524_EV\n",
      "Copiada: UIS11.UX_20240422232907_EV\n",
      "Copiada: UIS11.UX_20240501022527_EV\n",
      "Copiada: UIS11.UX_20240430200453_EV\n",
      "Copiada: UIS11.UX_20240401110557_EV\n",
      "Copiada: UIS11.UX_20240412041552_EV\n",
      "Copiada: UIS11.UX_20240413124701_EV\n",
      "Copiada: UIS11.UX_20240424111853_EV\n",
      "Copiada: UIS11.UX_20240418155823_EV\n",
      "Copiada: UIS11.UX_20240425182745_EV\n",
      "Copiada: UIS11.UX_20240418115907_EV\n",
      "Copiada: UIS11.UX_20240508233437_EV\n",
      "Copiada: UIS11.UX_20240509020905_EV\n",
      "Copiada: UIS11.UX_20240417180806_EV\n",
      "Copiada: UIS11.UX_20240403023253_EV\n",
      "Copiada: UIS11.UX_20240402232915_EV\n",
      "Copiada: UIS11.UX_20240430093006_EV\n",
      "Copiada: UIS11.UX_20240418003958_EV\n",
      "Copiada: UIS11.UX_20240430030147_EV\n",
      "Copiada: UIS11.UX_20240421153332_EV\n",
      "Copiada: UIS11.UX_20240401101019_EV\n",
      "Copiada: UIS11.UX_20240415105801_EV\n",
      "Copiada: UIS11.UX_20240422105153_EV\n",
      "Copiada: UIS11.UX_20240407071212_EV\n",
      "Copiada: UIS11.UX_20240429111838_EV\n",
      "Copiada: UIS11.UX_20240403013809_EV\n",
      "Copiada: UIS11.UX_20240422090416_EV\n",
      "Copiada: UIS11.UX_20240416071032_EV\n",
      "Copiada: UIS11.UX_20240429172905_EV\n",
      "Copiada: UIS11.UX_20240417061204_EV\n",
      "Copiada: UIS11.UX_20240417204031_EV\n",
      "Copiada: UIS11.UX_20240425051722_EV\n",
      "Copiada: UIS11.UX_20240430150512_EV\n",
      "Copiada: UIS11.UX_20240502200132_EV\n",
      "Copiada: UIS11.UX_20240425213433_EV\n",
      "Copiada: UIS11.UX_20240513011643_EV\n",
      "Copiada: UIS11.UX_20240417205018_EV\n",
      "Copiada: UIS11.UX_20240426035521_EV\n",
      "Copiada: UIS11.UX_20240423032500_EV\n",
      "Copiada: UIS11.UX_20240401064732_EV\n",
      "Copiada: UIS11.UX_20240512015957_EV\n",
      "Copiada: UIS11.UX_20240405071216_EV\n",
      "Copiada: UIS11.UX_20240501093151_EV\n",
      "\n",
      " Archivo HDF5 creado:\n",
      "E:/TG/BADASI/Versiones\\REDNE_20251219_063016.hdf5\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# ================== CONFIG ==================\n",
    "HDF5_PLANTILLA = r\"E:/TG/BADASI/REDNE_plantilla.hdf5\"\n",
    "CSV_FILTRO = r\"E:/TG/BADASI/REDNE.csv\"\n",
    "OUTPUT_DIR = r\"E:/TG/BADASI/Versiones\"\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "fecha = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "OUTPUT_HDF5 = os.path.join(\n",
    "    OUTPUT_DIR,\n",
    "    f\"REDNE_{fecha}.hdf5\"\n",
    ")\n",
    "\n",
    "# ================== CARGA CSV ==================\n",
    "df = pd.read_csv(CSV_FILTRO)\n",
    "df[\"trace_name\"] = df[\"trace_name\"].astype(str)\n",
    "\n",
    "trazas_filtradas = set(df[\"trace_name\"].unique())\n",
    "\n",
    "print(f\"Trazas a incluir: {len(trazas_filtradas)}\")\n",
    "\n",
    "# ================== PROCESO HDF5 ==================\n",
    "with h5py.File(HDF5_PLANTILLA, \"r\") as f_in, \\\n",
    "     h5py.File(OUTPUT_HDF5, \"w\") as f_out:\n",
    "\n",
    "    # Crear grupo /data\n",
    "    grp_out = f_out.create_group(\"data\")\n",
    "    grp_in = f_in[\"data\"]\n",
    "\n",
    "    for trace in trazas_filtradas:\n",
    "\n",
    "        if trace not in grp_in:\n",
    "            print(f\" Traza no encontrada: {trace}\")\n",
    "            continue\n",
    "\n",
    "        dset_in = grp_in[trace]\n",
    "\n",
    "        # -------- Copiar dataset --------\n",
    "        dset_out = grp_out.create_dataset(\n",
    "            trace,\n",
    "            data=dset_in[:],\n",
    "            compression=\"gzip\"\n",
    "        )\n",
    "\n",
    "        # -------- Copiar atributos originales --------\n",
    "        for k, v in dset_in.attrs.items():\n",
    "            dset_out.attrs[k] = v\n",
    "\n",
    "        # -------- Sobrescribir / agregar atributos desde CSV --------\n",
    "        fila = df[df[\"trace_name\"] == trace].iloc[0]\n",
    "\n",
    "        for col in df.columns:\n",
    "            if col == \"trace_name\":\n",
    "                continue\n",
    "            dset_out.attrs[col] = str(fila[col])\n",
    "\n",
    "        print(f\"Copiada: {trace}\")\n",
    "\n",
    "print(\"\\n Archivo HDF5 creado:\")\n",
    "print(OUTPUT_HDF5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seisbench-py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
